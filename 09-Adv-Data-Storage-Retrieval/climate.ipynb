{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Column('id', INTEGER(), table=<measurement>, primary_key=True, nullable=False),\n",
       " 'station': Column('station', TEXT(), table=<measurement>),\n",
       " 'date': Column('date', TEXT(), table=<measurement>),\n",
       " 'prcp': Column('prcp', FLOAT(), table=<measurement>),\n",
       " 'tobs': Column('tobs', FLOAT(), table=<measurement>)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The schema and table can be viewed at https://sqliteonline.com/\n",
    "#  Or by installing DB Browser for SQLite\n",
    "dict(Measurement.__table__.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Column('id', INTEGER(), table=<station>, primary_key=True, nullable=False),\n",
       " 'station': Column('station', TEXT(), table=<station>),\n",
       " 'name': Column('name', TEXT(), table=<station>),\n",
       " 'latitude': Column('latitude', FLOAT(), table=<station>),\n",
       " 'longitude': Column('longitude', FLOAT(), table=<station>),\n",
       " 'elevation': Column('elevation', FLOAT(), table=<station>)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Station.__table__.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x27efc74db38>,\n",
       " 'elevation': 3.0,\n",
       " 'longitude': -157.8168,\n",
       " 'name': 'WAIKIKI 717.2, HI US',\n",
       " 'id': 1,\n",
       " 'latitude': 21.2716,\n",
       " 'station': 'USC00519397'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the row's columns and data in dictionary format\n",
    "first_row = session.query(Station).first()\n",
    "first_row.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x27ef7098b70>,\n",
       " 'date': '2010-01-01',\n",
       " 'prcp': 0.08,\n",
       " 'id': 1,\n",
       " 'station': 'USC00519397',\n",
       " 'tobs': 65.0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the row's columns and data in dictionary format\n",
    "first_row = session.query(Measurement).first()\n",
    "first_row.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta as td\n",
    "lastyear = dt.date.today() - td(365)\n",
    "#today = dt.date.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2016-08-23\n",
      "2021 2021 <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import and_\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "#  prec_data = session.query(Measurement.date > last_year).limit(5).all()\n",
    "last_entry = session.query(Measurement).order_by(Measurement.date.desc())\n",
    "\n",
    "#  Print the date from the last 15 entries\n",
    "# for i in last_entry.limit(15).all():\n",
    "#     print(i.date)\n",
    "\n",
    "last_entry_year = last_entry.first().__dict__['date']\n",
    "prev_year = (dt.datetime.strptime(last_entry_year, \"%Y-%m-%d\") -td(365)).strftime(\"%Y-%m-%d\")\n",
    "print(type(prev_year), prev_year)\n",
    "prec_data = session.query(Measurement.date, Measurement.prcp).filter(\n",
    "    and_(Measurement.date >= prev_year, Measurement.prcp != None))\n",
    "# prec_data = session.query(Measurement).all()\n",
    "x_val, y_val = zip(*prec_data)\n",
    "\n",
    "# x_val = []\n",
    "# y_val = []\n",
    "# for i, j in prec_data:\n",
    "#     x_val.append(dt.datetime.strptime(i, \"%Y-%m-%d\"))\n",
    "#     y_val.append(j)\n",
    "# Give our graph axis labels\n",
    "# plt.xlabel(\"Date\")\n",
    "# plt.ylabel(\"Precipitation\")\n",
    "# plt.bar(x_val, y_val)\n",
    "# plt.show()\n",
    "\n",
    "print(len(x_val), len(y_val), type(x_val))\n",
    "\n",
    "df = pd.DataFrame({\"Date\" : x_val,\n",
    "                   \"Precipitation\" : y_val})\n",
    "df.set_index('Date', inplace=True)\n",
    "#df.sort_values(by=['Date'])\n",
    "df.sort_index(inplace=True)\n",
    "df.plot(kind='bar', alpha=0.75, rot=30)\n",
    "#df.to_csv(\"fileOne.csv\", index=True, header=True)\n",
    "# df1 = df.head(150)\n",
    "# df1.plot(kind='bar', alpha=0.75, rot=30)\n",
    "# plt.gca().xaxis_date()\n",
    "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y/%m/%d'))\n",
    "# plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "#  max(y_val)\n",
    "# for p in prec_data:\n",
    "#     print(p)\n",
    "# a\n",
    "\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "\n",
    "# Sort the dataframe by date\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "# Rotate the xticks for the dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stations = 9\n",
      "Station names:\n",
      "\tWAIKIKI 717.2, HI US\n",
      "\tKANEOHE 838.1, HI US\n",
      "\tKUALOA RANCH HEADQUARTERS 886.9, HI US\n",
      "\tPEARL CITY, HI US\n",
      "\tUPPER WAHIAWA 874.3, HI US\n",
      "\tWAIMANALO EXPERIMENTAL FARM, HI US\n",
      "\tWAIHEE 837.5, HI US\n",
      "\tHONOLULU OBSERVATORY 702.2, HI US\n",
      "\tMANOA LYON ARBO 785.2, HI US\n"
     ]
    }
   ],
   "source": [
    "# How many stations are available in this dataset?\n",
    "total_stations = session.query(Station).count()\n",
    "st = session.query(Station)\n",
    "print(f\"Total stations = {total_stations}\")\n",
    "print(\"Station names:\")\n",
    "for s in st:\n",
    "    print(f\"\\t{s.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT station.id AS station_id, station.station AS station_station, station.name AS station_name, count(measurement.prcp) AS \"Count\" \n",
      "FROM station JOIN measurement ON station.station = measurement.station GROUP BY station.name ORDER BY \"Count\" DESC\n",
      "\n",
      "counts 2772, Station_id: 7 name: WAIHEE 837.5, HI US\n",
      "counts 2696, Station_id: 2 name: KANEOHE 838.1, HI US\n",
      "counts 2685, Station_id: 1 name: WAIKIKI 717.2, HI US\n",
      "counts 2572, Station_id: 6 name: WAIMANALO EXPERIMENTAL FARM, HI US\n",
      "counts 2484, Station_id: 9 name: MANOA LYON ARBO 785.2, HI US\n",
      "counts 1937, Station_id: 3 name: KUALOA RANCH HEADQUARTERS 886.9, HI US\n",
      "counts 1932, Station_id: 8 name: HONOLULU OBSERVATORY 702.2, HI US\n",
      "counts 683, Station_id: 4 name: PEARL CITY, HI US\n",
      "counts 342, Station_id: 5 name: UPPER WAHIAWA 874.3, HI US\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import func\n",
    "\n",
    "# What are the most active stations?\n",
    "# List the stations and the counts in descending order.\n",
    "st_join = session.query(\n",
    "    Station.id, Station.station, Station.name, func.count(Measurement.prcp).label('Count')\n",
    ").join(\n",
    "    # tell SQLAlchemy to join the tables without foreign key\n",
    "    Measurement,Station.station==Measurement.station\n",
    ").group_by(\n",
    "    Station.name\n",
    ").order_by(\n",
    "    #  Forward reference to label attached above\n",
    "sqlalchemy.desc('Count')\n",
    ")\n",
    "\n",
    "print(st_join)\n",
    "print()\n",
    "for st_id, st, st_name, meas_cnt in st_join:\n",
    "    print(f\"counts {meas_cnt}, Station_id: {st_id} name: {st_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station USC00519281 WAIHEE 837.5, HI US recorded\n",
      "\t Lowest temp of 54.0, avg temp of 7.2e+01 and max temp of 85.0\n"
     ]
    }
   ],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "act_st_id = st_join.first()\n",
    "temp_q = session.query(\n",
    "    func.min(Measurement.tobs),\n",
    "    func.avg(Measurement.tobs),\n",
    "    func.max(Measurement.tobs)).filter(Measurement.station == act_st_id.station)\n",
    "print(f\"Station {act_st_id.station} {act_st_id.name} recorded\")\n",
    "min_t, avg_t, max_t = temp_q.first()\n",
    "print(\"\\t Lowest temp of {}, avg temp of {:2.2} and max temp of {}\".format(min_t, avg_t, max_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(62.0, 69.57142857142857, 74.0)]\n"
     ]
    }
   ],
   "source": [
    "# Write a function called `calc_temps` that will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62.0, 69.15384615384616, 77.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
