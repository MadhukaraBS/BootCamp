{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt instead.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Column('id', INTEGER(), table=<measurement>, primary_key=True, nullable=False),\n",
       " 'station': Column('station', TEXT(), table=<measurement>),\n",
       " 'date': Column('date', TEXT(), table=<measurement>),\n",
       " 'prcp': Column('prcp', FLOAT(), table=<measurement>),\n",
       " 'tobs': Column('tobs', FLOAT(), table=<measurement>)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  The schema and table can be viewed at https://sqliteonline.com/\n",
    "#  Or by installing DB Browser for SQLite\n",
    "dict(Measurement.__table__.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Column('id', INTEGER(), table=<station>, primary_key=True, nullable=False),\n",
       " 'station': Column('station', TEXT(), table=<station>),\n",
       " 'name': Column('name', TEXT(), table=<station>),\n",
       " 'latitude': Column('latitude', FLOAT(), table=<station>),\n",
       " 'longitude': Column('longitude', FLOAT(), table=<station>),\n",
       " 'elevation': Column('elevation', FLOAT(), table=<station>)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Station.__table__.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x27efc74db38>,\n",
       " 'elevation': 3.0,\n",
       " 'longitude': -157.8168,\n",
       " 'name': 'WAIKIKI 717.2, HI US',\n",
       " 'id': 1,\n",
       " 'latitude': 21.2716,\n",
       " 'station': 'USC00519397'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the row's columns and data in dictionary format\n",
    "first_row = session.query(Station).first()\n",
    "first_row.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_sa_instance_state': <sqlalchemy.orm.state.InstanceState at 0x27ef7098b70>,\n",
       " 'date': '2010-01-01',\n",
       " 'prcp': 0.08,\n",
       " 'id': 1,\n",
       " 'station': 'USC00519397',\n",
       " 'tobs': 65.0}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the row's columns and data in dictionary format\n",
    "first_row = session.query(Measurement).first()\n",
    "first_row.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta as td\n",
    "lastyear = dt.date.today() - td(365)\n",
    "#today = dt.date.today().strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> 2016-08-23\n",
      "2021 2021 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import and_\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "#  prec_data = session.query(Measurement.date > last_year).limit(5).all()\n",
    "last_entry = session.query(Measurement).order_by(Measurement.date.desc())\n",
    "\n",
    "#  Print the date from the last 15 entries\n",
    "# for i in last_entry.limit(15).all():\n",
    "#     print(i.date)\n",
    "\n",
    "last_entry_year = last_entry.first().__dict__['date']\n",
    "prev_year = (dt.datetime.strptime(last_entry_year, \"%Y-%m-%d\") -td(365)).strftime(\"%Y-%m-%d\")\n",
    "print(type(prev_year), prev_year)\n",
    "prec_data = session.query(Measurement.date, Measurement.prcp).filter(\n",
    "    and_(Measurement.date >= prev_year, Measurement.prcp != None))\n",
    "# prec_data = session.query(Measurement).all()\n",
    "# x_val, y_val = zip(*prec_data)\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "for i, j in prec_data:\n",
    "    x_val.append(dt.datetime.strptime(i, \"%Y-%m-%d\"))\n",
    "    y_val.append(j)\n",
    "# Give our graph axis labels\n",
    "# plt.xlabel(\"Date\")\n",
    "# plt.ylabel(\"Precipitation\")\n",
    "# plt.bar(x_val, y_val)\n",
    "# plt.show()\n",
    "\n",
    "print(len(x_val), len(y_val), type(x_val))\n",
    "\n",
    "df = pd.DataFrame({\"Date\" : x_val,\n",
    "                   \"Precipitation\" : y_val})\n",
    "df.set_index('Date', inplace=True)\n",
    "#df.sort_values(by=['Date'])\n",
    "df.sort_index(inplace=True)\n",
    "df.plot(kind='bar', alpha=0.75, rot=30)\n",
    "#df.to_csv(\"fileOne.csv\", index=True, header=True)\n",
    "# df1 = df.head(150)\n",
    "# df1.plot(kind='bar', alpha=0.75, rot=30)\n",
    "# plt.gca().xaxis_date()\n",
    "# plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y/%m/%d'))\n",
    "# plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "#  max(y_val)\n",
    "# for p in prec_data:\n",
    "#     print(p)\n",
    "# a\n",
    "\n",
    "\n",
    "\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "\n",
    "# Sort the dataframe by date\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "\n",
    "# Rotate the xticks for the dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-02 2017-09-02\n"
     ]
    }
   ],
   "source": [
    "# Calculate the date 1 year ago from today\n",
    "today = dt.date.today()\n",
    "last_year = today - td(365)\n",
    "#  last_year = last_year.strftime(\"%Y-%m-%d\")\n",
    "print(today, last_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a query to retrieve the data and precipitation scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "prcp_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many stations are available in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the most active stations?\n",
    "# List the stations and the counts in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(62.0, 69.57142857142857, 74.0)]\n"
     ]
    }
   ],
   "source": [
    "# Write a function called `calc_temps` that will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(62.0, 69.15384615384616, 77.0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
